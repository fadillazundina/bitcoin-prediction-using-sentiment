{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIBRARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'Data/Data Sentimen/Raw Data/Validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def read_csv_files(folder_path):\n",
    "    dfs = []\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "            df = pd.read_csv(file_path, on_bad_lines=\"skip\")\n",
    "            dfs.append(df)\n",
    "\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "sentimen = read_csv_files(folder_path)\n",
    "\n",
    "print(sentimen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sentimen\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "```\n",
    "def clean_tweet_text(raw_text):\n",
    "    cleaned_text = re.sub(r'[^\\x00-\\x7F]+', '', raw_text)\n",
    "    cleaned_text = re.sub(r'https?:\\/\\/\\S+', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r',+$', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'@\\w+', '', cleaned_text)\n",
    "    return cleaned_text.strip()\n",
    "\n",
    "df['full_text'] = df['full_text'].apply(clean_tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['full_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{df['full_text'][2]}\\n{df['full_text'][3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = pd.DataFrame({'date': df['created_at'], 'tweet': df['full_text'], 'labels': None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean['tweet'] = data_clean['tweet'].apply(clean_tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean.to_excel('Data/Data Sentimen/Clean Data/data_clean-validation.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('Data/Data Sentimen/Clean Data/data_clean-validation.xlsx')\n",
    "df.drop(index=3, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LABELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "class AutoLabeling:\n",
    "    def __init__(self) -> None:\n",
    "        self.client = AzureOpenAI(\n",
    "            api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "            api_version=\"2024-02-01\",\n",
    "            azure_endpoint=os.getenv(\"API_BASE\")\n",
    "        )\n",
    "        self.deployment_name = os.getenv(\"DEPLOYMENT_NAME\")\n",
    "\n",
    "    def request_generate(self, prompt):\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.deployment_name,\n",
    "                messages=prompt,\n",
    "                temperature=0.4,\n",
    "                max_tokens=2000\n",
    "            )\n",
    "            text = response.choices[0].message.content.replace(' .', '.').strip()\n",
    "            return text\n",
    "        except Exception as e:\n",
    "            print(\"An error occurred:\", e)\n",
    "            return None\n",
    "\n",
    "    def process_tweets(self, dates, tweets):\n",
    "        df = pd.DataFrame({'date': dates, 'tweet': tweets})\n",
    "        df['labels'] = None  # Initialize the labels column\n",
    "\n",
    "        for i, tweet in tqdm(enumerate(df['tweet']), total=len(df), desc=\"Processing tweets\"):\n",
    "            system_message = {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\"\"\"Anda adalah seorang manusia biasa yang ahli dalam bahasa, tugas anda adalah memberikan label dari kalimat twitter dengan kategori 'positif' 'negatif' atau 'netral'\n",
    "                pastikan hanya memberikan label dari kalimatnya saja, Selalu pastikan untuk memberi 1 label untuk setiap text yang saya inputkan.\n",
    "                Gunakan huruf kapital hanya di awal nama label\"\"\")\n",
    "            }\n",
    "\n",
    "            user_message_content = f\"Berikut adalah teks yang harus kamu labeli\\nText: {tweet}\\nLabel:\"\n",
    "            user_message = {'role': 'user', 'content': user_message_content}\n",
    "            prompt_message = [system_message, user_message]\n",
    "\n",
    "            label = self.request_generate(prompt_message)\n",
    "            if label is not None:\n",
    "                df.at[i, 'labels'] = label\n",
    "            else:\n",
    "                df.at[i, 'labels'] = \"Error\"\n",
    "\n",
    "        return df\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "auto_labeling = AutoLabeling()\n",
    "processed_df = auto_labeling.process_tweets(df['date'], df['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = processed_df.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_labels = ['Positif', 'Negatif', 'Netral']\n",
    "\n",
    "filtered_df = df[df['labels'].isin(allowed_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_excel('Data/Data Sentimen/Labeled Data/labelled-validation.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
